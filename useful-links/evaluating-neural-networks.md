# Evaluating Neural Networks

The most common ways of evaluating a neural network are the training loss, validation loss, training accuracy, and validation accuracy plots. These are essential steps for evaluating the robustness of your model but also the level of fit \(e.g. overfit\). Yellowbrick offers more intuitive visual diagnostic tools that extend the Scikit API.  The main dependencies are: [scikit-learn](http://scikit-learn.org/stable/) and [matplotlib](https://matplotlib.org/).

What makes yellowbrick different from matplotlib or seaborn or plotly is that it's the only visulization that does model visulization, directly show you the performace of models and makes coding much easier and shorter.

* [Evaluating NNets using YellowBrick](https://towardsdatascience.com/evaluating-keras-neural-network-performance-using-yellowbrick-visualizations-ad65543f3174)
* [Confusion matrix with matplotlib and yellowbrick](https://juan0001.github.io/Why-I-use-Python-and-yellowbrick-for-my-data-science-project/)

